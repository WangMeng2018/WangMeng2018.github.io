<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>鱼咸滚酱</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/"/>
  <updated>2020-02-22T08:21:21.820Z</updated>
  <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/</id>
  
  <author>
    <name>鱼咸滚酱</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Report: A Survey on Knowledge Graphs- Representation, Acquisition and Applications</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/</id>
    <published>2020-02-21T15:38:10.000Z</published>
    <updated>2020-02-22T08:21:21.820Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications"><a href="#A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications" class="headerlink" title="A Survey on Knowledge Graphs- Representation, Acquisition and Applications"></a>A Survey on Knowledge Graphs- Representation, Acquisition and Applications</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>​        本文对知识图谱进行了全面的综述，主要涵盖了四个方面：<strong>知识图谱表示学习（knowledge graph representation learning）、知识获取与补全（knowledge acquisition and completion）、时序知识图谱（temporal knowledge graph）、知识感知应用（knowledge-aware applications）</strong>。知识图谱嵌入从表示空间（representation space）、得分函数（scoring function）、编码模型（encoding models）和辅助信息（auxiliary information）四个方面进行组织。另外整理了一些筛选后的数据集和开源库。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>​        知识图谱是事实的结构化表示，由实体、关系和语义描述组成。实体可以是现实世界的对象和抽象概念，关系表示实体之间的关联，实体及其关系的语义描述包含定义良好的类型和属性。属性图或性质图被广泛使用，其中节点和关系具有属性或性质。</p><p>​        <strong>知识图谱</strong>与<strong>知识库</strong>是同义的，只是略有不同。当考虑知识图谱的图结构时，知识图谱可以看作是一个图。当它涉及到形式语义时，它可以作为解释和推断事实的知识库。知识库实例和知识图谱如图1所示。知识可以用事实的三元组形式来表达（头实体，关系，尾实体）或者（主语，谓语，宾语）(head, relation,tail)或 (subject, predicate,object) 。</p><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/1.png" title="avatar"><p>​        基于知识图谱的研究主要集中在知识表示学习(KRL)和知识图谱嵌入(KGE)两个方面。具体的知识获取任务包括知识图谱补全(KGC)、三元组分类、实体识别和关系提取。</p><h2 id="2-Overview"><a href="#2-Overview" class="headerlink" title="2. Overview"></a>2. Overview</h2><h3 id="2-1-A-Brief-History-of-Knowledge-Bases"><a href="#2-1-A-Brief-History-of-Knowledge-Bases" class="headerlink" title="2.1 A Brief History of Knowledge Bases"></a>2.1 A Brief History of Knowledge Bases</h3><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/2.png" title="avatar"><h3 id="2-2-Definitions-and-Notations"><a href="#2-2-Definitions-and-Notations" class="headerlink" title="2.2 Definitions and Notations"></a>2.2 Definitions and Notations</h3><ol><li><strong>定义1：</strong> 知识图谱获取信息并将其集成到本体中，应用推理引擎获得新知识。</li><li><strong>定义2：</strong>知识图谱是由实体和关系构成的多关系图，实体和关系分别被视为节点和不同类型的边。</li></ol><h3 id="2-3-Categorization-of-Research-on-Knowledge-Graph"><a href="#2-3-Categorization-of-Research-on-Knowledge-Graph" class="headerlink" title="2.3 Categorization of Research on Knowledge Graph"></a>2.3 Categorization of Research on Knowledge Graph</h3><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/3.png" title="avatar"><ol><li>知识表示学习(Knowledge Representation Learning，KRL）</li></ol><p>​        将KRL分为<strong>表示空间、评分函数、编码模型和辅助信息</strong>四个方面，为开发KRL模型提供了清晰的工作流程。具体的内容包括:</p><ul><li>关系和实体所表示的表示空间;</li><li>度量事实三元组似然性的评分函数；</li><li>用于表示和学习关系交互的编码模型;</li><li>嵌入方法所集成的辅助信息。</li></ul><p>​        表示学习包括点向空间、流形、复向量空间、高斯分布和离散空间。评分指标一般分为<strong>基于距离的评分函数和基于相似度匹配的评分函数</strong>。目前的研究集中在编码模型，包括线性/双线性模型，因式分解和神经网络。辅助信息包括文本信息、视觉信息和类型信息。</p><ol start="2"><li>知识获取任务分为三类</li></ol><p>​        关系提取和实体发现。第一个用于扩展现有的知识图谱，而其他两个用于从文本中发现新知识(即关系和实体)。KGC分为以下几类: 基于嵌入的排序、关系路径推理、基于规则的推理和元关系学习。实体发现包括识别、消歧、类型化和对齐。关系提取模型利用了注意力机制、图卷积网络、对抗性训练、强化学习、深度残差学习和迁移学习。</p><ol start="3"><li>时序知识图谱</li></ol><p>​        包含了表示学习的时态信息。对时间嵌入、实体动态、时序关系依赖、时序逻辑推理四个领域进行分类。</p><ol start="4"><li>知识感知应用</li></ol><p>​        包括自然语言理解(NLU)、问题回答、推荐系统和各种真实世界的任务，这些应用注入知识以改进表示学习。</p><h2 id="3-Knowledge-Representation-Learning"><a href="#3-Knowledge-Representation-Learning" class="headerlink" title="3. Knowledge Representation Learning"></a>3. Knowledge Representation Learning</h2><p>​        KRL在文献中也被称为KGE、多关系学习和统计关系学习。（原文：KRL is also known as KGE, multi-relation learning, and statistical relational learning in the literature.）</p><h3 id="3-1-Representation-Space"><a href="#3-1-Representation-Space" class="headerlink" title="3.1 Representation Space"></a>3.1 Representation Space</h3><p>​        表示学习的关键是学习低维分布式嵌入的实体和关系。</p><ol><li>Point-Wise Space：Point-wise Euclidean space用于表示实体和关系，嵌入到向量或矩阵空间中，或捕获其交互关系。 </li><li>Complex Vector Space：复向量空间能够捕获对称和不对称关系。</li><li>Gaussian Distribution：将实体和关系嵌入到多维高斯分布中。</li><li>Manifold and Group：流形是一个拓扑空间，它可以用集合理论定义为具有邻域的一组点，而群是抽象代数中定义的代数结构。</li></ol><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/4.png" title="avatar"><h3 id="3-2-Scoring-Function"><a href="#3-2-Scoring-Function" class="headerlink" title="3.2 Scoring Function"></a>3.2 Scoring Function</h3><p>​        评分函数用于度量事实的可信度，在基于能量的学习框架中也称为能量函数。能量学习的目的是学习能量函数。基于能量的学习目标学习能量函数Eθ(x)参数化θ采取x作为输入,以确保正样本分数高于负样本。</p><p>​        评分函数主要有两种：基于距离的(图4(a))和基于相似性的(图4(b))函数，用于度量事实的合理性。基于距离的评分函数通过计算实体之间的距离来衡量事实的合理度，其中使用较多的是关系为h+r≈t的翻译函数。基于语义相似度的评分方法是通过语义匹配来衡量事实的合理性，通常采用乘法公式，即 $h^T M_r ≈ t^T$ ,转换头尾部附近的实体表示空间。</p><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/5.png" title="avatar"><h3 id="3-3-Encoding-Models"><a href="#3-3-Encoding-Models" class="headerlink" title="3.3 Encoding Models"></a>3.3 Encoding Models</h3><p>​        对实体和关系的交互进行编码的模型:    </p><ol><li>线性模型通过将头部实体投射到接近尾部实体的表示空间中，将关系表示为线性/双线性映射。</li><li>因子分解的目的是将关系数据分解为低秩矩阵进行表示学习。</li><li>神经网络用非线性神经激活和更复杂的网络结构来编码关系数据。</li></ol><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/6.png" title="avatar"><h3 id="3-4-Embedding-with-Auxiliary-Information"><a href="#3-4-Embedding-with-Auxiliary-Information" class="headerlink" title="3.4 Embedding with Auxiliary Information"></a>3.4 Embedding with Auxiliary Information</h3><p>​        为了促进更有效的知识表示，多模态嵌入将诸如文本描述、类型约束、关系路径和视觉信息等外部信息与知识图谱本身结合起来。</p><h3 id="3-5-Summary"><a href="#3-5-Summary" class="headerlink" title="3.5 Summary"></a>3.5 Summary</h3><p>​        开发一个新的KRL模型主要需要解决以下四个问题:</p><ol><li>选择哪个表示空间;</li><li>如何测量特定空间中三元组的合理度;</li><li>采用何种编码模型对关系交互进行建模;</li><li>是否利用辅助信息。</li></ol><h2 id="4-Knowledge-Acquisition"><a href="#4-Knowledge-Acquisition" class="headerlink" title="4. Knowledge Acquisition"></a>4. Knowledge Acquisition</h2><p>​        知识获取的目的是从非结构化文本中构造知识图谱，补全已有的知识图，发现和识别实体和关系。</p><h3 id="4-1-Knowledge-Graph-Completion"><a href="#4-1-Knowledge-Graph-Completion" class="headerlink" title="4.1 Knowledge Graph Completion"></a>4.1 Knowledge Graph Completion</h3><p>​        基于知识图谱不完备性的特点，提出了一种新的知识图谱三元组生成方法。典型的子任务包括链路预测、实体预测和关系预测。</p><p>​        对KGC的初步研究主要集中在学习低维嵌入进行三元组预测。综述中将这些方法称为<strong>基于嵌入的方法</strong>。然而，它们大多数都没有捕捉到多步关系。因此，最近的工作转向探索多步骤的关系路径和合并逻辑规则，分别称为<strong>关系路径推理</strong>和<strong>基于规则的推理</strong>。三元组分类是KGC的一个相关任务，它评估了一个事实三元组分类的正确性。</p><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/7.png" title="avatar"><h3 id="4-2-Entity-Discovery"><a href="#4-2-Entity-Discovery" class="headerlink" title="4.2 Entity Discovery"></a>4.2 Entity Discovery</h3><p>​        将基于实体的知识获取分为几个细分的任务，即实体识别、实体消歧、实体类型和实体对齐。</p><ol><li>Entity Recognition：Entity recognition或者named entity recognition (NER)用于识别文本中的实体。</li><li>Entity Typing：实体类型包括粗糙和精细类型，后者使用树结构化类型目录，作为多类别和多标签分类。</li><li>Entity Disambiguation：Entity disambiguation或者entity linking，是将实体名称连接到知识图谱中特定的实体节点。</li><li>Entity Alignment：实体对齐是融合多个异构知识图谱。</li></ol><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/8.png" title="avatar"><h3 id="4-3-Relation-Extraction"><a href="#4-3-Relation-Extraction" class="headerlink" title="4.3 Relation Extraction"></a>4.3 Relation Extraction</h3><p>​        关系抽取是从纯文本中抽取未知关系事实并将其加入到知识图谱中，是自动构建大规模知识图谱的关键。</p><h3 id="4-4-Summary"><a href="#4-4-Summary" class="headerlink" title="4.4 Summary"></a>4.4 Summary</h3><ol><li><p>知识图谱补全：</p><p>​        完成了现有实体之间缺失的链接，或者推断出给定实体和关系查询的实体。基于嵌入的KGC方法通常依赖于三元组表示学习来捕获语义，并对完成的候选排序。基于嵌入的推理仍然停留在个体关系层面，由于忽略了知识图谱的符号性，缺乏可解释性，使得复杂推理能力较差。符号学与嵌入相结合的混合方法结合了基于规则的推理，克服了知识图谱的稀疏性，提高了嵌入的质量，促使有效的规则注入，并引入了可解释的规则。</p></li><li><p>实体发现：</p><p>​        从文本中获取面向实体的知识，将知识融合到知识图谱中。</p></li><li><p>关系抽取：</p><p>​        在距离监督的假设下存在噪声模式，尤其是在不同领域的文本语料库中。因此，弱监督关系提取对于减轻噪声标记的影响是很重要的。</p></li></ol><h2 id="5-Temporal-Knowledge-Graph"><a href="#5-Temporal-Knowledge-Graph" class="headerlink" title="5. Temporal Knowledge Graph"></a>5. Temporal Knowledge Graph</h2><p>​        当前知识图谱研究多集中在静态知识图上，事实不随时间变化，对知识图谱的时间动态研究较少。然而时间信息是非常重要的，因为结构化的知识只在一个特定的时期内存在，而事实的演变遵循一个时间序列。最近的研究开始将时间信息引入到KRL和KGC中，与之前的静态知识图相比，这被称为时序知识图。同时对时间嵌入和关系嵌入进行了研究。</p><ol><li><p>Temporal Information Embedding</p></li><li><p>Entity Dynamics</p></li><li><p>Temporal Relational Dependency</p></li><li><p>Temporal Logical Reasoning</p></li></ol><h2 id="6-Knowledge-aware-Application"><a href="#6-Knowledge-aware-Application" class="headerlink" title="6. Knowledge-aware Application"></a>6. Knowledge-aware Application</h2><ol><li><p>Natural Language Understanding：知识感知NLU将结构化的知识注入到统一的语义空间中，增强语言表示能力。</p></li><li><p>Question Answering：</p><ul><li>Single-fact QA</li><li>Multi-hop Reasoning</li></ul></li><li><p>Recommender Systems</p></li></ol><h2 id="7-F-UTURE-D-IRECTIONS"><a href="#7-F-UTURE-D-IRECTIONS" class="headerlink" title="7. F UTURE D IRECTIONS"></a>7. F UTURE D IRECTIONS</h2><ol><li>Complex Reasoning 复杂推理</li><li>Uniﬁed Framework 统一框架</li><li>Interpretability 可解释性</li><li>Scalability 可扩展性</li><li>Knowledge Aggregation 知识聚合</li><li>Automatic Construction and Dynamics 自动构建和动态知识图谱</li></ol><h2 id="8-Resources"><a href="#8-Resources" class="headerlink" title="8. Resources"></a>8. Resources</h2><img src="/2020/02/21/Report-A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications/9.png" title="avatar"><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://mp.weixin.qq.com/s/0f5E82utl-faCpmvrDoPEg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/0f5E82utl-faCpmvrDoPEg</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;A-Survey-on-Knowledge-Graphs-Representation-Acquisition-and-Applications&quot;&gt;&lt;a href=&quot;#A-Survey-on-Knowledge-Graphs-Representation-Acqu
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Knowledge Graph" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Knowledge-Graph/"/>
    
  </entry>
  
  <entry>
    <title>Report: HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/18/Report-HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/18/Report-HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization/</id>
    <published>2020-02-18T09:17:50.000Z</published>
    <updated>2020-02-18T16:33:10.287Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization"><a href="#HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization" class="headerlink" title="HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization"></a>HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization</h1><h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>​        HIBERT：HIerachical Bidirectional Encoder Representations from Transformers</p><p>​        整体思路：抽取式摘要，借鉴了Transformer的思想，利用大量的无标注数据进行预训练，学习句子和文档的表达，进而进行筛选句子作为摘要内容。</p><h2 id="二、模型"><a href="#二、模型" class="headerlink" title="二、模型"></a>二、模型</h2><img src="/2020/02/18/Report-HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization/1.png" title="avatar"><h3 id="2-1-Document-Representation"><a href="#2-1-Document-Representation" class="headerlink" title="2.1 Document Representation"></a>2.1 Document Representation</h3><p>​        为了获取文档的表达，这里使用了两个编码器。一个是句子编码器，用于转换文档中的句子；另一个是文档编码器，根据上下文语句学习句子表达。两者都使用Transformer，每一个词向量随机初始化，并且采用了sine-cosine位置编码；其次，Transformer会将词编码转换成一个高层表达序列，默认最后一个隐藏层表元素作为句子表示，比如<eos>位置的表示；接着每个句子的表示，都会加上一个位置编码，这个位置编码与句子中词语的位置编码相同；最后，获取结合上下文信息的句子表示。</eos></p><h3 id="2-2-Pre-training"><a href="#2-2-Pre-training" class="headerlink" title="2.2 Pre-training"></a>2.2 Pre-training</h3><p>使用双向信息，大致分两步：</p><ol><li>Document Masking</li></ol><p>​    以15%的概率Mask句子，一个被Masked的句子，会做如下处理，三种方式中选择一种：80%的语句会将其中的每一个词语包括标点都转换成[Mask]标识；10%的语句会保持不变，这种方式能够模拟测试时不Mask的情况；10%的语句会随机替换成其他语句，这种方式可以添加一些噪音，提高模型的鲁棒性。</p><ol start="2"><li>Sentence Prediction</li></ol><p>​    被Masked的语句的索引会被记录下来。首先，使用前面的编码器获得语句的上下文信息表示；在预测时，一个一个词语的进行预测，第一个默认是<bos>，在第j步时，输入前j-1个词语的信息以及该句子的上下文信息表示。这里与原来的Transformer稍有不同，原来使用编码器和解码器中的上下文信息表示，而这里只是用解码器中的上下文信息。</bos></p><img src="/2020/02/18/Report-HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization/2.png" title="avatar"><h3 id="2-3-Extractive-Summarization"><a href="#2-3-Extractive-Summarization" class="headerlink" title="2.3 Extractive Summarization"></a>2.3 Extractive Summarization</h3><p>​        建模成序列标注问题，在编码器后加一个线性层和一个SoftMax。</p><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>​        模型训练大致分为三个阶段：第一个阶段，开放域的预训练，使用大量的无特定领域的无标注数据；第二个阶段，特定域的预训练，使用专门数据集进行预训练，比如用于文本摘要的数据集；第三个阶段，微调HIBERT进行语句序列标注的预测。</p><p>​        实验效果不错。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HIBERT-Document-Level-Pre-training-of-Hierarchical-Bidirectional-Transformers-for-Document-Summarization&quot;&gt;&lt;a href=&quot;#HIBERT-Document-
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Text Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Text-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Report: STRASS: A Light and Effective Method for Extractive Summarization Based on Sentence Embeddings</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/18/Report-STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/18/Report-STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings/</id>
    <published>2020-02-18T09:01:47.000Z</published>
    <updated>2020-02-18T09:15:09.242Z</updated>
    
    <content type="html"><![CDATA[<h1 id="STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings"><a href="#STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings" class="headerlink" title="STRASS: A Light and Effective Method for Extractive Summarization Based on Sentence Embeddings"></a>STRASS: A Light and Effective Method for Extractive Summarization Based on Sentence Embeddings</h1><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>​        STRASS: Summarization by TRAnsformation Selection and Scoring</p><p>​        整体思路：抽取式摘要，选择句子Embedding与文档Embedding最接近的句子。模型会学习一个文档Embedding的转换，并最大化抽取摘要与真实摘要的相似度。</p><h2 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h2><p>​        摘要分成两类：生成式摘要和抽取式摘要。</p><ol><li>生成式摘要：生成新的文本来概括文档。可以建模成Seq-Seq的问题。典型模型有PGN。</li><li>抽取式摘要：两类方法解决，一个是序列标注，标注是否作为摘要的一部分；另一个是排序，越重要的句子排名越高。</li><li>两者结合：先抽取式选择句子，再用生成式方法重写他们。</li></ol><h2 id="三、模型"><a href="#三、模型" class="headerlink" title="三、模型"></a>三、模型</h2><p>​        模型总体分为四步：</p><img src="/2020/02/18/Report-STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings/1.png" title="avatar"><p>​        第一步，利用单层MLP将文档Embedding转换成特定形式；</p><p>​        第二步，句子选择生成摘要，句子选择时会提供一个阈值；</p><img src="/2020/02/18/Report-STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings/2.png" title="avatar"><p>​        第三步，生成的摘要的近似表示；</p><img src="/2020/02/18/Report-STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings/3.png" title="avatar"><p>​        第四步，计算与真实摘要的相似度，再反向传播。这里还考虑了一个压缩比的问题，系数越大，越倾向于生成短摘要。</p><img src="/2020/02/18/Report-STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings/4.png" title="avatar"><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>​        缺点：不能处理多主题文档的摘要问题；没有考虑摘要句子的位置信息。</p><p>​        优点：速度快，CPU就能够训练。</p><p>​        提出了一个新的CASS的法语数据集。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;STRASS-A-Light-and-Effective-Method-for-Extractive-Summarization-Based-on-Sentence-Embeddings&quot;&gt;&lt;a href=&quot;#STRASS-A-Light-and-Effectiv
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Text Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Text-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Report: Sentence Centrality Revisited for Unsupervised Summarization</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/18/Report-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/18/Report-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/</id>
    <published>2020-02-18T06:40:01.000Z</published>
    <updated>2020-02-18T08:53:29.815Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Sentence-Centrality-Revisited-for-Unsupervised-Summarization"><a href="#Sentence-Centrality-Revisited-for-Unsupervised-Summarization" class="headerlink" title="Sentence Centrality Revisited for Unsupervised Summarization"></a>Sentence Centrality Revisited for Unsupervised Summarization</h1><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>​        PACSUM：Position-Augmented Centrality based Summarization</p><p>​        整体思路：抽取式摘要，总体还是基于图的排序算法，调整了句子中心度的计算方法。使用BERT来进行句子表示，可以更好地捕获句子意义；将原来的无向图换成有向图，将一条无向边转换成两条有向边。</p><h2 id="二、模型"><a href="#二、模型" class="headerlink" title="二、模型"></a>二、模型</h2><p>​        模型总体分为两大部分：有向图构建和句子相似度计算。</p><h3 id="1-有向图"><a href="#1-有向图" class="headerlink" title="1. 有向图"></a>1. 有向图</h3><p>​        将原来的无向图换成有向图，将一条无向边转换成两条有向边，只是在原来相似度的基础上分别乘以一个不同的系数，这是基于两个句子的连接对两者中心度的贡献是受他们相对位置的影响的，越靠前的句子中心度越高。句子中心度的计算公式如下：</p><img src="/2020/02/18/Report-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/1.png" title="avatar"><p>​        另外，为了减少超参数数量，令两个系数之和等于1。而且第一个系数偏向于负数，说明，与前面句子的相似度会降低该句子的中心度。</p><h3 id="2-相似度计算"><a href="#2-相似度计算" class="headerlink" title="2. 相似度计算"></a>2. 相似度计算</h3><p>​        第一步：利用微调的BERT对句子进行编码；</p><p>​        第二步：为了微调BERT，使用了一个句子级的分布假设作为微调的目标函数。借鉴负采样的思想，将特定句子的前一句和后一句作为正例，语料中的其他句子作为负例。目标函数如下：</p><img src="/2020/02/18/Report-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/2.png" title="avatar"><p>其中，两个向量表示是参数不同的BERT得到的。</p><p>​        第三步：相似度直接有两个向量的点乘得到，点乘的效果优于余弦相似度。Beta系数决定了相似度低于多少才被设置为0。</p><img src="/2020/02/18/Report-Sentence-Centrality-Revisited-for-Unsupervised-Summarization/3.png" title="avatar"><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>​        代码：<a href="https://github.com/mswellhao/PacSum">https://github.com/mswellhao/PacSum</a></p><p>​        实验效果很好，还没来得及看代码，有兴趣看一下。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Sentence-Centrality-Revisited-for-Unsupervised-Summarization&quot;&gt;&lt;a href=&quot;#Sentence-Centrality-Revisited-for-Unsupervised-Summarization
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Text Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Text-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Report: Self-Supervised Learning for Contextualized Extractive Summarization</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/17/Report-Self-Supervised-Learning-for-Contextualized-Extractive-Summarization/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/17/Report-Self-Supervised-Learning-for-Contextualized-Extractive-Summarization/</id>
    <published>2020-02-17T06:46:50.000Z</published>
    <updated>2020-02-17T06:56:21.329Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Self-Supervised-Learning-for-Contextualized-Extractive-Summarization"><a href="#Self-Supervised-Learning-for-Contextualized-Extractive-Summarization" class="headerlink" title="Self-Supervised Learning for Contextualized Extractive Summarization"></a>Self-Supervised Learning for Contextualized Extractive Summarization</h1><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>​        引入三个辅助预训练方法Mask、Replace、Switch，以自监督的方式来捕获文档级的上下文信息，属于抽取式摘要方式。</p><p>​        代码：https:// github.com/hongwang600/Summarization</p><h2 id="二、模型"><a href="#二、模型" class="headerlink" title="二、模型"></a>二、模型</h2><p>​        这里使用了一个基础模型：一个句子编码器和一个文档级的自注意力机制。句子编码器是一个双向的LSTM，输入是句子序列的Embedding，输出是句子表示；再经过Self-Attention层，输出学习了全局上下文信息的句子表示；再通过线性层判断是否选择该句子。</p><img src="/2020/02/17/Report-Self-Supervised-Learning-for-Contextualized-Extractive-Summarization/1.png" title="avatar"><h2 id="三、预训练方法"><a href="#三、预训练方法" class="headerlink" title="三、预训练方法"></a>三、预训练方法</h2><ol><li><p>Mask</p><p>​        Mask任务就是从候选池中预测Masked的句子。首先，以一定的概率Mask文档中的句子，并将Masked句子存入候选池。其次，用相同的句子编码器获取候选池中句子的表示。接着，模型需要预测每一个Mask位置缺失的句子，会先将Masked句子用<unk>代替，并计算其结合上下文信息的表示。最后，再计算两个表示的余弦相似度。</unk></p><img src="/2020/02/17/Report-Self-Supervised-Learning-for-Contextualized-Extractive-Summarization/2.png" title="avatar"><p>​        为了训练模型，使用排序的损失函数来最大化预测句子与其他句子的边距。</p><img src="/2020/02/17/Report-Self-Supervised-Learning-for-Contextualized-Extractive-Summarization/3.png" title="avatar"></li><li><p>Replace</p><p>​        以一定的概率用其他文档的句子替换本文档中的句子，并使用一个线性层来预测句子是否被替换。</p><img src="/2020/02/17/Report-Self-Supervised-Learning-for-Contextualized-Extractive-Summarization/4.png" title="avatar"></li><li><p>Switch</p><p>​        与Replace类似，只不过是与同一文档中的句子进行交换。</p></li></ol><h2 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h2><p>​        效果的确提升了，而且收敛速度更快。Switch方法的表现最好，但是感觉没有达到读者预想的目标。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Self-Supervised-Learning-for-Contextualized-Extractive-Summarization&quot;&gt;&lt;a href=&quot;#Self-Supervised-Learning-for-Contextualized-Extracti
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Text Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Text-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Report:Video Skimming: Taxonomy and Comprehensive Survey</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/17/Report-Video-Skimming-Taxonomy-and-Comprehensive-Survey/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/17/Report-Video-Skimming-Taxonomy-and-Comprehensive-Survey/</id>
    <published>2020-02-17T06:23:21.000Z</published>
    <updated>2020-02-17T06:41:07.625Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Video-Skimming-Taxonomy-and-Comprehensive-Survey"><a href="#Video-Skimming-Taxonomy-and-Comprehensive-Survey" class="headerlink" title="Video Skimming: Taxonomy and Comprehensive Survey"></a>Video Skimming: Taxonomy and Comprehensive Survey</h1><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>​        Video Skimming视频略读，又称为动态视频摘要。静态视频摘要是指提取视频中的关键帧，而动态视频摘要是生成短视频。可以利用内部信息和外部信息。内部信息是指视频、音频和文本；外部信息是指用户评论、用户打分、视频回顾（类似于影评）。</p><h2 id="二、系统架构"><a href="#二、系统架构" class="headerlink" title="二、系统架构"></a>二、系统架构</h2><img src="/2020/02/17/Report-Video-Skimming-Taxonomy-and-Comprehensive-Survey/1.png" title="avatar"><ol><li><p>Segmentation：将当前视频分成更小的单元，称为skim     unit。将视频分成最小的可理解单元，并单独处理。最小的可理解单元是指可以传达特定含义的帧数最少的单元。</p></li><li><p>Importance computation：计算skim unit的重要性。</p></li><li><p>User preferences：设定用户需求，比如skim长度、skim类型（强调或者总括）。</p></li><li><p>Skim unit selection：选择需要的skim unit，去重。</p></li></ol><h2 id="三、分类"><a href="#三、分类" class="headerlink" title="三、分类"></a>三、分类</h2><ol><li>不同领域的视频摘要说明以及评估标准：</li></ol><img src="/2020/02/17/Report-Video-Skimming-Taxonomy-and-Comprehensive-Survey/2.png" title="avatar"><ol start="2"><li>不同类型的视频摘要的发展趋势：</li></ol><img src="/2020/02/17/Report-Video-Skimming-Taxonomy-and-Comprehensive-Survey/3.png" title="avatar"><ol start="3"><li>论文中还有详细的数据集划分。</li></ol><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><h4 id="挑战："><a href="#挑战：" class="headerlink" title="挑战："></a>挑战：</h4><ol><li>深度学习方法缺乏大量的训练数据；</li><li>长视频摘要问题；</li><li>实时摘要问题；</li><li>多模态或者跨媒体摘要问题。</li></ol><h4 id="未来方向："><a href="#未来方向：" class="headerlink" title="未来方向："></a>未来方向：</h4><ol><li>确定最佳摘要长度；</li><li>视频摘要的可理解性，确定最小视频单元的时间长度；</li><li>通用领域的视频摘要问题；</li><li>为其他任务合成数据集；</li><li>评估标准的问题。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Video-Skimming-Taxonomy-and-Comprehensive-Survey&quot;&gt;&lt;a href=&quot;#Video-Skimming-Taxonomy-and-Comprehensive-Survey&quot; class=&quot;headerlink&quot; tit
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Video Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Video-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Report:A Simple Theoretical Model of Importance for Summarization</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/16/Report-A-Simple-Theoretical-Model-of-Importance-for-Summarization/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/16/Report-A-Simple-Theoretical-Model-of-Importance-for-Summarization/</id>
    <published>2020-02-16T12:24:21.000Z</published>
    <updated>2020-02-18T08:45:26.045Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-Simple-Theoretical-Model-of-Importance-for-Summarization"><a href="#A-Simple-Theoretical-Model-of-Importance-for-Summarization" class="headerlink" title="A Simple Theoretical Model of Importance for Summarization"></a>A Simple Theoretical Model of Importance for Summarization</h1><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>​        整体思路：摘要的主要目的就是在损失最小信息量的情况下，最大限度表达原文信息量，因此基于信息论来研究摘要任务是合适的。然而信息论着重于研究信息的不确定性，容易忽略语言中的语义信息，因此直接应用信息论不适合。论文里将文本切分成最基本的语义单元，语义单元负责语义部分，而信息论只需要关注由语义单元构成的文本信息即可。（语义单元可以是字符、词、n-gram、具有更复杂语义语法内容的单元，也称为原子信息块。）文本则是用这些基本语义单元的概率分布来表示。</p><h2 id="二、框架"><a href="#二、框架" class="headerlink" title="二、框架"></a>二、框架</h2><p>​        论文从四个不同的角度，在本质上对摘要本身做了分析。分别是冗余度(redundancy)，相关性(relevance)，informativeness，重要性(importance)。其中，重要性是论文新突出的理念，它结合了其余三个概念的内容，并进行了公式化。</p><h3 id="1-相关性Relevance"><a href="#1-相关性Relevance" class="headerlink" title="1. 相关性Relevance"></a>1. 相关性Relevance</h3><p>​        目前大部分模型对摘要抽取或生成的目标都可近似为相关性。对于有监督学习训练来说，抽取式摘要的训练数据标注了哪些句子是摘要句。最后任务转化为对每个句子做二分类问题，而生成式摘要的seq2seq模型中，也是与标注的人工摘要进行语义单元上的差异计算。对于无监督学习来说，大部分的方法的建模目标都是相关性。</p><p>​        通过阅读摘要，应该降低对原文的不确定感，摘要文本应当以最小的信息损失来推断原文文档。从统计学角度来看，摘要和原文档都各自满足一定的概率分布，而分布之间的接近程度可以简单的使用交叉熵（cross-entropy）衡量。CE指的是交叉熵的函数，注意到这里有个负号，因为交叉熵越小，表示摘要和文档的差异越小，那么相关性应当越强。<br>​<br>​                                                                            REL(S,D) = −CE(S,D)</p><h3 id="2-冗余度Redundancy"><a href="#2-冗余度Redundancy" class="headerlink" title="2. 冗余度Redundancy"></a>2. 冗余度Redundancy</h3><p>​        如果简单的使用相关性来对文档中的句子进行排序，然后选择相关性最高的某些句子来生成摘要，但由于相关性分数接近的句子表述的内容通常也是接近的，因此摘要的冗余度就会很高。而一个好的摘要应该是包含不同的信息，而不是大量相似的信息，而冗余度可以使用熵进行描述。</p><img src="/2020/02/16/Report-A-Simple-Theoretical-Model-of-Importance-for-Summarization/1.png" title="avatar"><p>​        那么冗余度可以表示为Red(S)=−H(S) 。建模的目标是冗余度尽量小，那么表示S SS的熵值越大，表示文本的不确定性越好，所包含的信息量也越大，对应的冗余度也就越小。</p><h3 id="3-信息量Informativeness"><a href="#3-信息量Informativeness" class="headerlink" title="3. 信息量Informativeness"></a>3. 信息量Informativeness</h3><p>​        根据论文的叙述，这个概念假设当前有一个背景知识库K，此时需要对文档D进行摘要抽取，那么候选摘要S对于K来说，应当新增尽可能多的信息，才能让读者在阅读摘要后获取最多的新信息。如果摘要句子说的都是用户早就知道的事情，那么阅读摘要没有给用户产生任何价值。</p><p>​        相关性和冗余度只是在当前处理文档的范围内进行建模，但是人类的语言是有庞大的常识库的。只使用相关性和冗余度有其局限性，因此才引入了informativeness的概念。那么如何度量这个概念呢？informativeness的目标是让S尽可能与K不同，同时K也是由语义单元组成的文本语料集合，因此也可以用Pk来表示K的概率分布，与相关性类似，使用交叉熵来衡量两个概率分布的差异性。</p><img src="/2020/02/16/Report-A-Simple-Theoretical-Model-of-Importance-for-Summarization/2.png" title="avatar"><h3 id="4-重要性Importance"><a href="#4-重要性Importance" class="headerlink" title="4. 重要性Importance"></a>4. 重要性Importance</h3><p>​        针对的是语义单元，目标是计算每个语义单元的重要性分数，在构造摘要时，根据每个语义单元的评分来丢弃不需要的语义单元。</p><img src="/2020/02/16/Report-A-Simple-Theoretical-Model-of-Importance-for-Summarization/3.png" title="avatar"><h3 id="5-整合四个维度"><a href="#5-整合四个维度" class="headerlink" title="5. 整合四个维度"></a>5. 整合四个维度</h3><img src="/2020/02/16/Report-A-Simple-Theoretical-Model-of-Importance-for-Summarization/4.png" title="avatar"><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>​        纯理论论文，没有具体模型，定性分析文本摘要的生成与评估。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/76492696" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/76492696</a></li><li><a href="https://blog.csdn.net/Forlogen/article/details/98963499" target="_blank" rel="noopener">https://blog.csdn.net/Forlogen/article/details/98963499</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;A-Simple-Theoretical-Model-of-Importance-for-Summarization&quot;&gt;&lt;a href=&quot;#A-Simple-Theoretical-Model-of-Importance-for-Summarization&quot; cl
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Text Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Text-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Report:A Study of Human Summaries of Scientific Articles</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/16/Report-A-Study-of-Human-Summaries-of-Scientific-Articles/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2020/02/16/Report-A-Study-of-Human-Summaries-of-Scientific-Articles/</id>
    <published>2020-02-16T11:58:24.000Z</published>
    <updated>2020-02-16T12:20:40.828Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-Study-of-Human-Summaries-of-Scientific-Articles"><a href="#A-Study-of-Human-Summaries-of-Scientific-Articles" class="headerlink" title="A Study of Human Summaries of Scientific Articles"></a>A Study of Human Summaries of Scientific Articles</h1><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>What the differences between human summaries and automatic summarizations?</p><ol><li><p>Human summaries have deeper insights, which can be used to imporve and adapt existing automatic summarization systems to the domian of scientific papers.</p></li><li><p>Human summaries tend to be long, detailed and contain headlines and figures from the origin papers.</p></li></ol><p>​Automatic summarization focuses on:</p><ol><li>automatic generation of relatively short summaries(150 - 200 words);</li><li>have an abstract-like structure, lacking other summarization constructs used by humans such as headlines and figures.;</li><li>most existing summarization methods of scientific papers rely on citations in order to pinpoint the import parts, but the citations volume of newly published papers is not enough to perform a similar analysis.</li></ol><p>Dataset for automatic scientific summarization: Scisumm, ScisummNet.</p><p>To solve the above problems, this paper studies a dataset for scientific summarizations, based on long human summaries authored by ShortScience.org users. The goal is to study the characteristics of human scientific summaries and propose to use the summaries published on blogs as a potential benchmark for automation. </p><h2 id="2-Dataset"><a href="#2-Dataset" class="headerlink" title="2. Dataset"></a>2. Dataset</h2><p>ShortScience is an open platform for publishing summaries of scientific papers in the domains of Computer Science, Physics and Biology. The website provides minimal instructions on how to write a summary and there is a large variation in summary length and structure.</p><p>How to process?</p><ol><li>Fetch 561 summaries associated with 491 papers;</li><li>Papers are from Arxiv, NeurIPS, ACL, Springer;</li><li>Utilize NLTK for word tokenization and sentence segmentation;</li><li>Use <a href="https://github.com/allenai/science-parse">Science-Parse</a> to extract the PDF text and outputs a Json record containing abstract text, metadata(such as authors and year), and a flat llist of the article sections;</li><li>Disregard sentences less than 20 characters, to minimize effect of parsing errors;</li><li>The mean summary length is 447 words, and the median is 312 words;</li><li>The average number of sentences per summary is 22.</li></ol><h2 id="3-Human-Summaries-Analysis"><a href="#3-Human-Summaries-Analysis" class="headerlink" title="3. Human Summaries Analysis"></a>3. Human Summaries Analysis</h2><h3 id="3-1-Summary-subjectivity"><a href="#3-1-Summary-subjectivity" class="headerlink" title="3.1 Summary subjectivity"></a>3.1 Summary subjectivity</h3><p>For assessing to what extent the summaries represent a subjective account of the origin scientific work:</p><ol><li>extract all sentences containing terms “i” or “my”;</li><li>130 summaries out of 561 summaries include such sentences;</li><li>5 cases errorneous, 53% neutral, 32% positive, 15% negative.</li></ol><p>When decide to publicly express their opinion on scientific work, they tend to present a positive or balanced view and not to criticize. People choose to summarize papers they deem valuable.</p><h3 id="3-2-Summary-coverage"><a href="#3-2-Summary-coverage" class="headerlink" title="3.2 Summary coverage"></a>3.2 Summary coverage</h3><p>To asses to what extent human summaries cover logical aspects of the papers:</p><ol><li>align each summary sentence to the sentence in the original paper most similar to it and with the category of that sentence;</li><li>paper sections hierarchy was restored and sub-section are merged into their containing high level section;</li><li>high level sections are as follows: Introduction, Related work, Method, Results, Experiments, Discussion, Conclusions, Future work, Unknown; (2051 out of 3421 article sections were assighed with a category while the rest were classified as Unknown)</li><li>section sentences inhert their containing section title;</li><li>experiment with three similarity methods: <ul><li>ROUGE-L</li><li>average of F1, ROUGE-1, ROUGE21 and ROUGE-L</li><li>cosine similarity over word vectors</li></ul></li></ol><img src="/2020/02/16/Report-A-Study-of-Human-Summaries-of-Scientific-Articles/1.png" title="avatar"><p>The weights are quite stable when using different similarities. A summarization algorithm can aim at assigning higher focus to more salient logical sections, reﬂecting how humans attend different sections in their summary.</p><h3 id="3-3-Summary-style"><a href="#3-3-Summary-style" class="headerlink" title="3.3 Summary style"></a>3.3 Summary style</h3><h4 id="3-3-1-Figures-inclusion"><a href="#3-3-1-Figures-inclusion" class="headerlink" title="3.3.1 Figures inclusion"></a>3.3.1 Figures inclusion</h4><p>Some human summaries include ﬁgures from the original paper including image captures of equations or tables. About 31% of the summaries include at least one such ﬁgure, with an average of 2 ﬁgures per summary.</p><p>We need to consider multi-modal summarization and no work now.</p><h4 id="3-3-2-Summary-Itemization"><a href="#3-3-2-Summary-Itemization" class="headerlink" title="3.3.2 Summary Itemization"></a>3.3.2 Summary Itemization</h4><p>Almost half of the summaries utilized some form of structuring using itemization (i.e., bullets or numbering)(编号或符号，代表逐条记录):</p><ol><li>with an average of 15 items per summary;</li><li>The average size of an item is 2 sentences. </li></ol><h4 id="3-3-3-Headlines"><a href="#3-3-3-Headlines" class="headerlink" title="3.3.3 Headlines"></a>3.3.3 Headlines</h4><p>About 35% of the summaries contain lines that start with “#”, which act as summary “headlines”.</p><img src="/2020/02/16/Report-A-Study-of-Human-Summaries-of-Scientific-Articles/2.png" title="avatar">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;A-Study-of-Human-Summaries-of-Scientific-Articles&quot;&gt;&lt;a href=&quot;#A-Study-of-Human-Summaries-of-Scientific-Articles&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
    
      <category term="Paper" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Paper/"/>
    
      <category term="Text Summarization" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Text-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>python使用json.dump的中文编码问题</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/10/10/python%E4%BD%BF%E7%94%A8json-dump%E7%9A%84%E4%B8%AD%E6%96%87%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/10/10/python使用json-dump的中文编码问题/</id>
    <published>2019-10-10T12:27:18.000Z</published>
    <updated>2019-10-10T12:34:42.148Z</updated>
    
    <content type="html"><![CDATA[<p>当json中有中文字符串时，直接<em>dump</em>会出错，需要在<em>open</em>函数中加上<em>encoding=‘utf-8’</em>，<em>dump</em>函数中加上<em>ensure_ascii=False</em>。  </p><img src="/2019/10/10/python使用json-dump的中文编码问题/1.png" title="avatar">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当json中有中文字符串时，直接&lt;em&gt;dump&lt;/em&gt;会出错，需要在&lt;em&gt;open&lt;/em&gt;函数中加上&lt;em&gt;encoding=‘utf-8’&lt;/em&gt;，&lt;em&gt;dump&lt;/em&gt;函数中加上&lt;em&gt;ensure_ascii=False&lt;/em&gt;。  &lt;/p&gt;
&lt;img
      
    
    </summary>
    
    
      <category term="Python" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Linux安装JDK</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/28/Linux%E5%AE%89%E8%A3%85JDK/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/28/Linux安装JDK/</id>
    <published>2019-09-28T05:58:49.000Z</published>
    <updated>2019-09-28T06:00:58.772Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>先将jdk1.7的安装包下载到本地，在上传到Linux；</p></li><li><p>tar zxvf  jdk-7u80-linux-x64.tar.gz</p></li><li><p>vim ~/.bashrc</p></li><li><p>export JAVA_HOME=/home/wangmeng/jdk1.7.0_80<br>export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:<br>$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>export PATH=$PATH:$JAVA_HOME/bin</p></li><li><p>source ~/.bashrc</p></li><li><p>java -version</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;先将jdk1.7的安装包下载到本地，在上传到Linux；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;tar zxvf  jdk-7u80-linux-x64.tar.gz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;vim ~/.bashrc&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;
      
    
    </summary>
    
    
      <category term="Java" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Java/"/>
    
      <category term="Ubuntu" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Visual Studio中C++使用Scanf报错</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/27/Visual-Studio%E4%B8%ADC-%E4%BD%BF%E7%94%A8Scanf%E6%8A%A5%E9%94%99/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/27/Visual-Studio中C-使用Scanf报错/</id>
    <published>2019-09-27T01:14:01.000Z</published>
    <updated>2019-09-27T01:21:12.075Z</updated>
    
    <content type="html"><![CDATA[<p>解决办法：  </p><ol><li><p>在新建项目时，取消SDL前的勾号；  </p><img src="/2019/09/27/Visual-Studio中C-使用Scanf报错/1.png" title="avatar"></li><li><p>项目属性;<br>预处理器定义 编辑：增加首项：_CRT_SECURE_NO_WARNINGS  </p><img src="/2019/09/27/Visual-Studio中C-使用Scanf报错/2.png" title="avatar"></li><li><p>可以在代码生成中关闭安全检查。  </p><img src="/2019/09/27/Visual-Studio中C-使用Scanf报错/3.png" title="avatar"></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;解决办法：  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在新建项目时，取消SDL前的勾号；  &lt;/p&gt;
&lt;img src=&quot;/2019/09/27/Visual-Studio中C-使用Scanf报错/1.png&quot; title=&quot;avatar&quot;&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;项目属性;
      
    
    </summary>
    
    
      <category term="C++" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Tex中文乱码</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/26/Tex%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/26/Tex中文乱码/</id>
    <published>2019-09-26T01:44:02.000Z</published>
    <updated>2019-09-26T01:46:55.363Z</updated>
    
    <content type="html"><![CDATA[<p>加上带注释的语句：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;amsmath,amssymb&#125;</span><br><span class="line">\usepackage&#123;latexsym&#125;</span><br><span class="line">\usepackage&#123;CJK&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;CJK*&#125;&#123;GBK&#125;&#123;gsbn&#125;       # 需要添加</span><br><span class="line">文本内容</span><br><span class="line"></span><br><span class="line">\end&#123;CJK*&#125;                    # 需要添加</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;加上带注释的语句：  &lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/s
      
    
    </summary>
    
    
      <category term="Windows" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Windows/"/>
    
      <category term="Tex" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Tex/"/>
    
  </entry>
  
  <entry>
    <title>Tex中找不到.sty文件</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/25/Tex%E4%B8%AD%E6%89%BE%E4%B8%8D%E5%88%B0-sty%E6%96%87%E4%BB%B6/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/25/Tex中找不到-sty文件/</id>
    <published>2019-09-25T03:01:52.000Z</published>
    <updated>2019-09-25T03:05:19.997Z</updated>
    
    <content type="html"><![CDATA[<p>问题：Tex编译报错，找不到指定的.sty文件。  </p><p>解决办法：从网上下载对应的sty文件，并拷贝到当前.tex目录下。  </p><p>下载链接：<a href="https://searchcode.com/codesearch/view/31207532/#" target="_blank" rel="noopener">https://searchcode.com/codesearch/view/31207532/#</a>  </p><p>可以在View File Tree中搜索。  </p><img src="/2019/09/25/Tex中找不到-sty文件/1.png" title="avatar">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;问题：Tex编译报错，找不到指定的.sty文件。  &lt;/p&gt;
&lt;p&gt;解决办法：从网上下载对应的sty文件，并拷贝到当前.tex目录下。  &lt;/p&gt;
&lt;p&gt;下载链接：&lt;a href=&quot;https://searchcode.com/codesearch/view/3120753
      
    
    </summary>
    
    
      <category term="Windows" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Windows/"/>
    
      <category term="Tex" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Tex/"/>
    
  </entry>
  
  <entry>
    <title>WinEdt打开tex文件Reading Error</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/24/WinEdt%E6%89%93%E5%BC%80tex%E6%96%87%E4%BB%B6Reading-Error/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/24/WinEdt打开tex文件Reading-Error/</id>
    <published>2019-09-24T06:41:19.000Z</published>
    <updated>2019-09-24T06:44:48.814Z</updated>
    
    <content type="html"><![CDATA[<p>错误：WinEdt打开tex文件Reading Error。  </p><p>原因：因为.tex文件中包含了utf-8字符，而在打开的时候并没有指明utf-8打开方式。  </p><p>解决方案：  </p><img src="/2019/09/24/WinEdt打开tex文件Reading-Error/1.png" title="avatar"><p>参考链接：<br><a href="https://blog.csdn.net/garfielder007/article/details/51619821" target="_blank" rel="noopener">https://blog.csdn.net/garfielder007/article/details/51619821</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;错误：WinEdt打开tex文件Reading Error。  &lt;/p&gt;
&lt;p&gt;原因：因为.tex文件中包含了utf-8字符，而在打开的时候并没有指明utf-8打开方式。  &lt;/p&gt;
&lt;p&gt;解决方案：  &lt;/p&gt;
&lt;img src=&quot;/2019/09/24/WinEdt打开
      
    
    </summary>
    
    
      <category term="Windows" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Windows/"/>
    
      <category term="Tex" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Tex/"/>
    
  </entry>
  
  <entry>
    <title>Windows设置Notepad++为txt的默认打开方式</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/23/Windows%E8%AE%BE%E7%BD%AENotepad-%E4%B8%BAtxt%E7%9A%84%E9%BB%98%E8%AE%A4%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/23/Windows设置Notepad-为txt的默认打开方式/</id>
    <published>2019-09-23T03:25:18.000Z</published>
    <updated>2019-09-23T03:27:21.740Z</updated>
    
    <content type="html"><![CDATA[<ol><li>win+R，输入regedit打开注册表编辑器；</li><li>定位到 <em>HKEY_LOCAL_MACHINE\SOFTWARE\Classes\txtfile\shell\Open\command</em> 这个注册表下面；</li><li>右边有一个REG_SZ类型数据点右键修改为你的NotePad++安装目录；</li><li>修改数值数据为 (“D:\Notepad++\notepad++.exe %1”)；</li><li>系统默认为自带的NotePad打开<br>%SystemRoot%\system32\NOTEPAD.EXE %1，这个是默认的地址，如果想恢复系统默认情况，修改为此值。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;win+R，输入regedit打开注册表编辑器；&lt;/li&gt;
&lt;li&gt;定位到 &lt;em&gt;HKEY_LOCAL_MACHINE\SOFTWARE\Classes\txtfile\shell\Open\command&lt;/em&gt; 这个注册表下面；&lt;/li&gt;
&lt;li&gt;右边有
      
    
    </summary>
    
    
      <category term="软件" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/%E8%BD%AF%E4%BB%B6/"/>
    
      <category term="Windows" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>Windows安装XShell</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/22/Windows%E5%AE%89%E8%A3%85XShell/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/22/Windows安装XShell/</id>
    <published>2019-09-22T06:36:09.000Z</published>
    <updated>2019-09-22T06:37:49.404Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、下载安装"><a href="#一、下载安装" class="headerlink" title="一、下载安装"></a>一、下载安装</h1><p>可直接从官网下载免费版：<a href="https://www.netsarang.com/zh/" target="_blank" rel="noopener">https://www.netsarang.com/zh/</a>  </p><p>使用邮箱接受下载链接，直接安装。</p><h1 id="二、问题解决"><a href="#二、问题解决" class="headerlink" title="二、问题解决"></a>二、问题解决</h1><p>如果遇到问题，类似只能对当前安装的产品有效，说明之前安装版本没有删除干净，可以到到C盘，C:\Program Files (x86)\InstallShield Installation Information，删掉{F3FDFD5A-A201-407B-887F-399484764ECA}这个文件夹就可以，不一定是那个。可以备份全删，重新安装后在粘贴回去。  </p><p>参考链接：<br><a href="https://blog.csdn.net/qq_17758709/article/details/78920641" target="_blank" rel="noopener">https://blog.csdn.net/qq_17758709/article/details/78920641</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、下载安装&quot;&gt;&lt;a href=&quot;#一、下载安装&quot; class=&quot;headerlink&quot; title=&quot;一、下载安装&quot;&gt;&lt;/a&gt;一、下载安装&lt;/h1&gt;&lt;p&gt;可直接从官网下载免费版：&lt;a href=&quot;https://www.netsarang.com/zh/&quot; ta
      
    
    </summary>
    
    
      <category term="软件" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/%E8%BD%AF%E4%BB%B6/"/>
    
      <category term="Windows" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu下安装和使用GLPK</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/21/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8GLPK/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/21/Ubuntu下安装和使用GLPK/</id>
    <published>2019-09-21T06:12:46.000Z</published>
    <updated>2019-09-22T12:51:49.990Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、安装"><a href="#一、安装" class="headerlink" title="一、安装"></a>一、安装</h1><blockquote><ul><li>wget <a href="http://ftp.gnu.org/gnu/glpk/glpk-4.65.tar.gz" target="_blank" rel="noopener">http://ftp.gnu.org/gnu/glpk/glpk-4.65.tar.gz</a></li><li>tar -xzvf glpk-4.65.tar.gz</li><li>./configure</li><li>make</li><li>sudo make install</li></ul></blockquote><p>使用前可能还需要修改一下/etc/ld.so.conf.d/libc.conf文件</p><blockquote><ul><li>udo vim /etc/ld.so.conf.d/libc.conf</li><li>/usr/local/lib/  需要有/号在lib后面</li><li>sudo ldconfig /etc/ld.so.conf.d/lib.conf</li><li>sudo ldconfig /etc/ld.so.conf</li></ul></blockquote><h1 id="二、使用："><a href="#二、使用：" class="headerlink" title="二、使用："></a>二、使用：</h1><ol><li>编辑glpsolEx.mod文件： vim glpsolEx.mod</li><li>执行 glpsol -m glpsolEx.mod -o glpsolEx.sol ，将结果输出到 glpsolEx.sol中。</li><li>说明：glpsolEx.mod文件内容如下：  </li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Variables */</span>  </span><br><span class="line"><span class="keyword">var</span> x1 &gt;= <span class="number">0</span>;  </span><br><span class="line"><span class="keyword">var</span> x2 &gt;= <span class="number">0</span>;</span><br><span class="line"><span class="keyword">var</span> x3 &gt;= <span class="number">0</span>;  </span><br><span class="line"><span class="comment">/* Object function */</span>  </span><br><span class="line">maximize z: x1 + <span class="number">14</span>*x2 + <span class="number">6</span>*x3;  </span><br><span class="line"><span class="comment">/* Constrains */</span>  </span><br><span class="line">s.t. con1: x1 + x2 + x3 &lt;= <span class="number">4</span>;  </span><br><span class="line">s.t. con2: x1  &lt;= <span class="number">2</span>;  </span><br><span class="line">s.t. con3: x3  &lt;= <span class="number">3</span>;  </span><br><span class="line">s.t. con4: <span class="number">3</span>*x2 + x3  &lt;= <span class="number">6</span>;  </span><br><span class="line">end;</span><br></pre></td></tr></table></figure><p>参考链接:  </p><ul><li><a href="http://www.cnblogs.com/jostree/p/4156204.html" target="_blank" rel="noopener">http://www.cnblogs.com/jostree/p/4156204.html</a></li><li><a href="https://blog.csdn.net/danwuxie/article/details/80981169" target="_blank" rel="noopener">https://blog.csdn.net/danwuxie/article/details/80981169</a></li><li><a href="https://blog.csdn.net/zhuoyuezai/article/details/78844549" target="_blank" rel="noopener">https://blog.csdn.net/zhuoyuezai/article/details/78844549</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、安装&quot;&gt;&lt;a href=&quot;#一、安装&quot; class=&quot;headerlink&quot; title=&quot;一、安装&quot;&gt;&lt;/a&gt;一、安装&lt;/h1&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;wget &lt;a href=&quot;http://ftp.gnu.org/gnu/glpk/g
      
    
    </summary>
    
    
      <category term="Ubuntu" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Ubuntu/"/>
    
      <category term="GLPK" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/GLPK/"/>
    
  </entry>
  
  <entry>
    <title>Git上传100MB限制</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/21/Git%E4%B8%8A%E4%BC%A0100MB%E9%99%90%E5%88%B6/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/21/Git上传100MB限制/</id>
    <published>2019-09-21T06:07:54.000Z</published>
    <updated>2019-09-21T06:08:50.947Z</updated>
    
    <content type="html"><![CDATA[<p>Github只允许上传100MB的文件，如果超过，服务器会直接拒绝。</p><p>解决办法：  </p><ol><li>sudo git rm –cached 文件路径；</li><li>sudo git commit –amend -CHEAD;</li><li>sudo push -u origin master.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Github只允许上传100MB的文件，如果超过，服务器会直接拒绝。&lt;/p&gt;
&lt;p&gt;解决办法：  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sudo git rm –cached 文件路径；&lt;/li&gt;
&lt;li&gt;sudo git commit –amend -CHEAD;&lt;/li&gt;
&lt;li
      
    
    </summary>
    
    
      <category term="Git" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Git/"/>
    
      <category term="软件" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/%E8%BD%AF%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>you-get安装</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/19/you-get%E5%AE%89%E8%A3%85/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/19/you-get安装/</id>
    <published>2019-09-19T11:30:31.000Z</published>
    <updated>2019-09-19T02:05:14.158Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、安装"><a href="#一、安装" class="headerlink" title="一、安装"></a>一、安装</h1><p>使用<em>pip install you-get</em>命令安装即可。  </p><h1 id="二、视频下载"><a href="#二、视频下载" class="headerlink" title="二、视频下载"></a>二、视频下载</h1><ol><li><p>下载视频<br>打开cmd，输入”you-get+空格+视频url”即可下载。  </p></li><li><p>暂停  </p></li></ol><p><em>Ctrl+C</em>是中断下载任务。下次下载相同的视频时，默认继续上次未完成的下载（前提时未将上次下载的临时.download文件删除，否则重新下载），如已经完成则会自动跳过。  </p><ol start="3"><li>自定义下载名称和保存路径<br>使用-o（小写的o）设置保存路径，-O(大写的O)设置下载文件的名称。<br>例如：<em>you-get -o ./ -O test.mp4 <a href="https://www.youtube.com/example" target="_blank" rel="noopener">https://www.youtube.com/example</a></em>  </li></ol><h1 id="三、批量下载"><a href="#三、批量下载" class="headerlink" title="三、批量下载"></a>三、批量下载</h1><p>you-get支持批量下载，复制的是视频首页或者简介页的地址。</p><h1 id="四、本地播放"><a href="#四、本地播放" class="headerlink" title="四、本地播放"></a>四、本地播放</h1><p>本地播放器播放网页视频：让网页视频在本地播放，没有任何广告和评论部分。  </p><ol><li>进入视频播放器的安装目录：<em>cd D:\PotPlayer</em>  </li><li>输入以下参数：<em>ou-get -p xxx.exe url</em>  </li><li>比如： <em>you-get -p PotPlayerMini64.exe <a href="https://www.iqiyi.com/example.html" target="_blank" rel="noopener">https://www.iqiyi.com/example.html</a></em>  </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、安装&quot;&gt;&lt;a href=&quot;#一、安装&quot; class=&quot;headerlink&quot; title=&quot;一、安装&quot;&gt;&lt;/a&gt;一、安装&lt;/h1&gt;&lt;p&gt;使用&lt;em&gt;pip install you-get&lt;/em&gt;命令安装即可。  &lt;/p&gt;
&lt;h1 id=&quot;二、视频下载&quot;&gt;&lt;a
      
    
    </summary>
    
    
      <category term="软件" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/%E8%BD%AF%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Windows下IDEA无法识别JDK</title>
    <link href="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/16/Windows%E4%B8%8BIDEA%E6%97%A0%E6%B3%95%E8%AF%86%E5%88%ABJDK/"/>
    <id>https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/2019/09/16/Windows下IDEA无法识别JDK/</id>
    <published>2019-09-16T14:03:30.000Z</published>
    <updated>2019-09-16T14:04:30.692Z</updated>
    
    <content type="html"><![CDATA[<ol><li>首先确认已经安装jdk；</li><li>在IDEA菜单栏中选中File或者在初始界面的configuration中选择Project Structure；</li><li>弹出的对话框左边有一个SDK选项，单击；</li><li>点击+号，选择JDK；</li><li>定位到JDK安装目录下，比如：D:\Java\jdk1.8.0_91；<br>然后点击Apply，点击OK。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;首先确认已经安装jdk；&lt;/li&gt;
&lt;li&gt;在IDEA菜单栏中选中File或者在初始界面的configuration中选择Project Structure；&lt;/li&gt;
&lt;li&gt;弹出的对话框左边有一个SDK选项，单击；&lt;/li&gt;
&lt;li&gt;点击+号，选择JDK；&lt;
      
    
    </summary>
    
    
      <category term="Java" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Java/"/>
    
      <category term="Windows" scheme="https://github.com/WangMeng2018/WangMeng2018.github.io/tree/master/tags/Windows/"/>
    
  </entry>
  
</feed>
